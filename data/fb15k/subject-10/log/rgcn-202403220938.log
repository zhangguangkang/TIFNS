[2024-03-22 09:39:01,240] INFO: 

pretrain the aux triples...
[2024-03-22 09:39:54,310] INFO: GPU usage for embeddings 2819
[2024-03-22 09:39:54,859] INFO: GPU usage for backward 6851
[2024-03-22 09:39:54,875] INFO: Training for aux data: Epoch 0001 | Batch 0001 | Loss 0.6933 | Best MRR 0.0000 | [53.6 s]
[2024-03-22 09:39:55,245] INFO: GPU usage for embeddings 6855
[2024-03-22 09:39:55,679] INFO: GPU usage for backward 6855
[2024-03-22 09:39:55,679] INFO: Training for aux data: Epoch 0001 | Batch 0002 | Loss 0.6924 | Best MRR 0.0000 | [54.4 s]
[2024-03-22 09:39:56,029] INFO: GPU usage for embeddings 6855
[2024-03-22 09:39:56,459] INFO: GPU usage for backward 6855
[2024-03-22 09:39:56,459] INFO: Training for aux data: Epoch 0001 | Batch 0003 | Loss 0.6915 | Best MRR 0.0000 | [55.2 s]
[2024-03-22 09:39:56,815] INFO: GPU usage for embeddings 6855
[2024-03-22 09:39:57,262] INFO: GPU usage for backward 6855
[2024-03-22 09:39:57,262] INFO: Training for aux data: Epoch 0001 | Batch 0004 | Loss 0.6903 | Best MRR 0.0000 | [56.0 s]
[2024-03-22 09:39:57,613] INFO: GPU usage for embeddings 6855
[2024-03-22 09:39:58,048] INFO: GPU usage for backward 6855
[2024-03-22 09:39:58,048] INFO: Training for aux data: Epoch 0001 | Batch 0005 | Loss 0.6891 | Best MRR 0.0000 | [56.8 s]
[2024-03-22 09:39:58,397] INFO: GPU usage for embeddings 6855
[2024-03-22 09:39:58,833] INFO: GPU usage for backward 6855
[2024-03-22 09:39:58,838] INFO: Training for aux data: Epoch 0001 | Batch 0006 | Loss 0.6879 | Best MRR 0.0000 | [57.6 s]
[2024-03-22 09:39:59,178] INFO: GPU usage for embeddings 6855
[2024-03-22 09:39:59,610] INFO: GPU usage for backward 6855
[2024-03-22 09:39:59,610] INFO: Training for aux data: Epoch 0001 | Batch 0007 | Loss 0.6868 | Best MRR 0.0000 | [58.4 s]
[2024-03-22 09:39:59,943] INFO: GPU usage for embeddings 6855
[2024-03-22 09:40:00,359] INFO: GPU usage for backward 6855
[2024-03-22 09:40:00,359] INFO: Training for aux data: Epoch 0001 | Batch 0008 | Loss 0.6856 | Best MRR 0.0000 | [59.1 s]
[2024-03-22 09:40:00,539] INFO: GPU usage for embeddings 6855
[2024-03-22 09:40:00,849] INFO: GPU usage for backward 6855
[2024-03-22 09:40:00,859] INFO: Training for aux data: Epoch 0001 | Batch 0009 | Loss 0.6845 | Best MRR 0.0000 | [59.6 s]
[2024-03-22 09:40:10,892] INFO: GPU usage for embeddings 6853
[2024-03-22 09:40:11,304] INFO: GPU usage for backward 6853
[2024-03-22 09:40:11,313] INFO: Training for aux data: Epoch 0002 | Batch 0001 | Loss 0.6833 | Best MRR 0.0000 | [70.1 s]
[2024-03-22 09:40:11,642] INFO: GPU usage for embeddings 6855
[2024-03-22 09:40:12,090] INFO: GPU usage for backward 6855
[2024-03-22 09:40:12,090] INFO: Training for aux data: Epoch 0002 | Batch 0002 | Loss 0.6823 | Best MRR 0.0000 | [70.8 s]
[2024-03-22 09:40:12,460] INFO: GPU usage for embeddings 6853
[2024-03-22 09:40:12,882] INFO: GPU usage for backward 6853
[2024-03-22 09:40:12,892] INFO: Training for aux data: Epoch 0002 | Batch 0003 | Loss 0.6812 | Best MRR 0.0000 | [71.7 s]
[2024-03-22 09:40:13,264] INFO: GPU usage for embeddings 6855
[2024-03-22 09:40:13,700] INFO: GPU usage for backward 6855
[2024-03-22 09:40:13,700] INFO: Training for aux data: Epoch 0002 | Batch 0004 | Loss 0.6801 | Best MRR 0.0000 | [72.5 s]
[2024-03-22 09:40:14,047] INFO: GPU usage for embeddings 6853
[2024-03-22 09:40:14,488] INFO: GPU usage for backward 6853
[2024-03-22 09:40:14,488] INFO: Training for aux data: Epoch 0002 | Batch 0005 | Loss 0.6790 | Best MRR 0.0000 | [73.2 s]
[2024-03-22 09:40:14,843] INFO: GPU usage for embeddings 6855
[2024-03-22 09:40:15,269] INFO: GPU usage for backward 6855
[2024-03-22 09:40:15,278] INFO: Training for aux data: Epoch 0002 | Batch 0006 | Loss 0.6780 | Best MRR 0.0000 | [74.0 s]
[2024-03-22 09:40:15,618] INFO: GPU usage for embeddings 6853
[2024-03-22 09:40:16,059] INFO: GPU usage for backward 6853
[2024-03-22 09:40:16,059] INFO: Training for aux data: Epoch 0002 | Batch 0007 | Loss 0.6769 | Best MRR 0.0000 | [74.8 s]
[2024-03-22 09:40:16,401] INFO: GPU usage for embeddings 6855
[2024-03-22 09:40:16,842] INFO: GPU usage for backward 6855
[2024-03-22 09:40:16,842] INFO: Training for aux data: Epoch 0002 | Batch 0008 | Loss 0.6758 | Best MRR 0.0000 | [75.6 s]
[2024-03-22 09:40:17,006] INFO: GPU usage for embeddings 6853
[2024-03-22 09:40:17,340] INFO: GPU usage for backward 6853
[2024-03-22 09:40:17,346] INFO: Training for aux data: Epoch 0002 | Batch 0009 | Loss 0.6747 | Best MRR 0.0000 | [76.1 s]
[2024-03-22 09:40:17,408] INFO: Done pretrain aux triples. [76.2 s]
[2024-03-22 09:40:17,408] INFO: 

 Start to train the aux and inferred triples...
[2024-03-22 09:40:17,468] INFO: Done relabeled data [0.1 s]
[2024-03-22 09:40:18,993] INFO: Done build graph [1.6 s]
[2024-03-22 09:40:20,404] INFO: Done soft labels [3.0 s]
[2024-03-22 09:40:20,404] INFO: Some rule confidence: [0.277363657951355, 0.277363657951355, 0.277363657951355, 0.277363657951355, 0.277363657951355]
[2024-03-22 09:40:20,404] INFO: Some soft labels: [0.5624417662620544, 0.562483012676239, 0.5621974468231201, 0.5622754096984863, 0.5622393488883972]
[2024-03-22 09:40:20,404] INFO: 

 Train by batch...
